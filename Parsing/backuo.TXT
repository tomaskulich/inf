import sys
sys.path.insert(0,"../..")
from ply import *

RESERVED = {
  "import" : "IMPORT",
  "def": "DEF",
  "if": "IF",
  "return": "RETURN",
  "class" : "CLASS",
  }

tokens = (
    "IMPORT",
    "CLASS",
    "DEF",
    "IF",
    #"RETURN",
    "NEWLINE",
    "COMMENT",
    "WS",
    "STATEMENT",
    "NAME",
    "LPAR",
    "RPAR",
    "COLON",
    #"ENDMARKER",
    "COMMA"
    )

t_CLASS = r'class'
#t_COMMA = r','

NO_INDENT = 0
MAY_INDENT = 1
MUST_INDENT = 2

class my_indent():
    INDENT_LEVEL = 0
    def set_indent(self,arg1):
        self.INDENT_LEVEL = arg1
    
    def ret_indent(self):
        return self.INDENT_LEVEL
#INDENT_LEVEL = 0

premenna = my_indent()

def t_COMMA(t):
    r','
    return t

def t_WS(t):
    r' [ ]+ '
    # if t.lexer.at_line_start and t.lexer.paren_count == 0:
    #print("hodnota:",premenna.ret_indent())
    if premenna.ret_indent() == 2:
        if len(t.value) > 1:
            return t

def t_COLON(t):
    r':'
    premenna.set_indent(MUST_INDENT)
    #print(premenna.ret_indent())
    return t

def t_LPAR(t):
    r'\('
    return t

def t_RPAR(t):
    r'\)'
    return t

def t_NAME(t):
    r'[a-zA-Z_][a-zA-Z0-9_]*'
    #print("NAME MATCH:", t.value)
    t.type = RESERVED.get(t.value, "NAME")    # Check for reserved words
    return t

def t_STATEMENT(t):
    r'.+'
    #r'.*^[\ ]'
    t.type = RESERVED.get(t.value, "STATEMENT")    # Check for reserved words
    return t

def t_COMMENT(t):
    r"[ ]*\043[^\n]*"  # \043 is '#'
    return t

def t_NEWLINE(t):
    r'\n+'
    t.lexer.lineno += t.value.count("\n")
    if t.value == "\n\n":
        premenna.set_indent(NO_INDENT)
    return t

def t_error(t):
    print ("Illegal character '%s'" % t.value[0])
    t.lexer.skip(1)

lex.lex()

#parsing rules
def p_file_input(p):
    """file_input : stmt
                | file_input stmt
                | funcdef
                | file_input funcdef
                | classdef
                | file_input classdef
                  """
    if(len(p)==3):
        #p[0] = ((p[1]),(p[2]))
        p[0] = (p[1],p[2])
    else:
        p[0] = (p[1])
    
def p_stmt(p):
    """stmt : STATEMENT NEWLINE
            | NAME parameters NEWLINE
            | NAME STATEMENT NEWLINE
            | NAME
            | NAME NEWLINE
            | funcdef
            | IMPORT NAME NEWLINE
            | COMMENT NEWLINE
            | NEWLINE"""
    # simple_stmt is a list
    if len(p) == 4:
        #print("P: ",p[1],p[2],p[3])
        p[0] = p[1]+p[2]+p[3]
    elif len(p) == 3:
        p[0] = p[1]+p[2]
    else:
        p[0] = p[1]
    #print("A",p[0])


def p_funcdef(p):
    #"funcdef : DEF STATEMENT parameters COLON suite"
    "funcdef : DEF NAME parameters COLON suite"
    #p[0] = p[3]+p[5]
    #print("1:",p[1],"2:",p[2],"3:",p[3],"4:",p[4],"5:",p[5])
    p[0] = (p[1],p[2],p[3],p[4],p[5])
    #p[0] = ast.Function(None, p[2], tuple(p[3]), (), 0, None, p[5])

def p_classdef(p):
    "classdef : CLASS NAME parameters COLON suite"
    p[0] = (p[1],p[2],p[3],p[4],p[5])
    

def p_parameters(p):
    """parameters : LPAR RPAR
                  | LPAR varargslist RPAR"""
    if len(p) == 3:
        p[0] = p[1]+p[2]
    else:
        p[0] = (p[1],p[2],p[3])

def p_varargslist(p):
    """varargslist : varargslist COMMA NAME
                   | NAME"""
    if len(p) == 4:
        p[0] = (p[1],p[2],p[3])
    else:
        p[0] = (p[1])

def p_suite(p):
    """suite : NEWLINE stmts
             | WS stmt
             | WS funcdef
             """
    if len(p) == 2:
        p[0] = (p[1],p[2])
        #premenna.set_indent(0)
    else:
        p[0] = (p[1],p[2])
        premenna.set_indent(MUST_INDENT)
        #INDENT_LEVEL = MUST_INDENT

def p_stmts(p):
    """stmts : stmts WS stmt
             | WS stmt
             | NEWLINE stmt"""
    if len(p) == 4:
        p[0] = (p[1],p[2],p[3])
    else:
        p[0] = (p[1],p[2])

def p_error(e):
    print('error: %s'%e)

import ply.yacc as yacc
yacc.yacc()

# Combine Ply and my filters into a new lexer                    
f= open("input_for_ply.py", "r")
data = f.read()
print("PARSE:")
result = yacc.parse(data)
print(result)
import Tree
Tree.treeprint(result)
#import output
#output.treeprint(result)

((('print', ('(', ')'), '\n'), ('print', ('(', ')'), '\n')), ('print', ('(', ')'), '\n\n'))

# Give the lexer some input
lex.input(data)

print("----------------------------------")

# Tokenize
while True:
    tok = lex.token()
    if not tok: break      # No more input
    print(tok)